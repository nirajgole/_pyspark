{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27738,"status":"ok","timestamp":1700646362862,"user":{"displayName":"Abhijit Biswas","userId":"07763541842867693542"},"user_tz":-330},"id":"Qp90H1TrL2e0","outputId":"050571a7-c604-40ff-ba6f-f3f20fd8f20a"},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'google.colab'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# importing the required library\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# mounting google drive to Collab\u001b[39;00m\n\u001b[0;32m      5\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"]}],"source":["# importing the required library\n","from google.colab import drive\n","\n","# mounting google drive to Collab\n","drive.mount(\"/content/drive\")\n","# moving around in google drive\n","%cd drive/MyDrive\n","# Listing all the files/folders present\n","%ls\n","# moving around in google drive\n","%cd  Contents/\n","# Listing all the files/folders present\n","%ls"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":52372,"status":"ok","timestamp":1700646426936,"user":{"displayName":"Abhijit Biswas","userId":"07763541842867693542"},"user_tz":-330},"id":"QOcpNmQtL6_Q","outputId":"ca6cc718-10cd-43a6-db14-9086331a758d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting pyspark\n","  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n","Building wheels for collected packages: pyspark\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425344 sha256=e0c3af17deda50b34922e9066e3a8c05e46268f4e529309d2223257fcbf80a41\n","  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n","Successfully built pyspark\n","Installing collected packages: pyspark\n","Successfully installed pyspark-3.5.0\n"]}],"source":["# installing the pyspark library.\n","!pip install pyspark"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JbXCWFgTa59J"},"outputs":[],"source":["from google.colab import drive\n","\n","drive.mount(\"/content/drive\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":219},"executionInfo":{"elapsed":12109,"status":"ok","timestamp":1700646521192,"user":{"displayName":"Abhijit Biswas","userId":"07763541842867693542"},"user_tz":-330},"id":"7LQfNqDsL68-","outputId":"1adb7af3-db35-4a39-e2a6-a9870a3c818f"},"outputs":[{"data":{"text/html":["\n","            <div>\n","                <p><b>SparkSession - in-memory</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://ef608253bf92:4040\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.5.0</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local[*]</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>PySpark SQL Assignment 01</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "],"text/plain":["<pyspark.sql.session.SparkSession at 0x79be70f31480>"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# importing SparkSession from pyspark.sql library\n","from pyspark.sql import SparkSession\n","from pyspark.sql.types import *\n","from pyspark.sql.functions import col, regexp_extract, regexp_replace, split\n","\n","# What is the differnece between SparkSession and SparkContext\n","# SparkContext was the entry point for programming Spark before Spark 2.0. It represented the connection to a Spark cluster and was responsible for coordinating the execution of tasks.\n","# It was used to create RDDs (Resilient Distributed Datasets), which are the fundamental data structures in Spark for distributed computation.\n","# SparkContext handled low-level functionalities like distributing and scheduling tasks, managing memory, and interacting with storage systems.\n","# However, with the introduction of SparkSession, most of the functionality of SparkContext was encapsulated within the new session abstraction.\n","\n","# SparkSession is the entry point for programming Spark applications starting from Spark 2.0.\n","# It encapsulates both the SparkContext and additional context-related configuration.\n","# It provides a unified interface for working with structured data using DataFrames and Datasets, which offer optimizations and benefits over RDDs.\n","# SparkSession also manages various context-specific settings and configurations, like SQL configuration, Hive integration, and more.\n","# It simplifies the process of working with different Spark libraries (SQL, Streaming, MLlib, GraphX) by providing a consistent API.\n","\n","# initializing a SparkSession taking in consideration all the cores in local system and giving a name to the Application as \"SparkSession\"\n","spark = (\n","    SparkSession.builder.master(\"local[*]\")\n","    .appName(\"PySpark SQL Assignment 01\")\n","    .getOrCreate()\n",")\n","\n","# Printing out the value of spark variable that stores the spark session.\n","spark"]},{"cell_type":"markdown","metadata":{"id":"1eVjHP4EUcr4"},"source":["**Question 01**\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1486,"status":"ok","timestamp":1700646538284,"user":{"displayName":"Abhijit Biswas","userId":"07763541842867693542"},"user_tz":-330},"id":"7weIyH_oL63d"},"outputs":[],"source":["# Loading the dataset\n","ratingsRDD = spark.sparkContext.textFile(\n","    \"/content/drive/MyDrive/Contents/Pyspark/PySpark Dataframe/ratings.dat\"\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1700646597808,"user":{"displayName":"Abhijit Biswas","userId":"07763541842867693542"},"user_tz":-330},"id":"fxIXSfekPiur"},"outputs":[],"source":["# Define schema\n","schema_string = \"UserID MovieID Rating Timestamp\"\n","schema = StructType(\n","    [\n","        StructField(field_name, StringType(), True)\n","        for field_name in schema_string.split()\n","    ]\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2151,"status":"ok","timestamp":1700646627155,"user":{"displayName":"Abhijit Biswas","userId":"07763541842867693542"},"user_tz":-330},"id":"VzNdX9XHPl0a"},"outputs":[],"source":["# Create DataFrame\n","row_rdd = ratingsRDD.map(lambda x: x.split(\"::\")).map(\n","    lambda x: (x[0], x[1], x[2], x[3])\n",")\n","ratings = spark.createDataFrame(row_rdd, schema)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12541,"status":"ok","timestamp":1700646645963,"user":{"displayName":"Abhijit Biswas","userId":"07763541842867693542"},"user_tz":-330},"id":"IAzTXV_WPnbR","outputId":"fab1c1de-4617-48a0-dbc7-1fada2772144"},"outputs":[{"name":"stdout","output_type":"stream","text":["+------+-------+------+---------+\n","|UserID|MovieID|Rating|Timestamp|\n","+------+-------+------+---------+\n","|     1|   1193|     5|978300760|\n","|     1|    661|     3|978302109|\n","|     1|    914|     3|978301968|\n","|     1|   3408|     4|978300275|\n","|     1|   2355|     5|978824291|\n","|     1|   1197|     3|978302268|\n","|     1|   1287|     5|978302039|\n","|     1|   2804|     5|978300719|\n","|     1|    594|     4|978302268|\n","|     1|    919|     4|978301368|\n","|     1|    595|     5|978824268|\n","|     1|    938|     4|978301752|\n","|     1|   2398|     4|978302281|\n","|     1|   2918|     4|978302124|\n","|     1|   1035|     5|978301753|\n","|     1|   2791|     4|978302188|\n","|     1|   2687|     3|978824268|\n","|     1|   2018|     4|978301777|\n","|     1|   3105|     5|978301713|\n","|     1|   2797|     4|978302039|\n","+------+-------+------+---------+\n","only showing top 20 rows\n","\n"]}],"source":["# Show the output\n","ratings.show()"]},{"cell_type":"markdown","metadata":{"id":"ExEfT2GQUhU-"},"source":["**Question 02**\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":380,"status":"ok","timestamp":1700646689742,"user":{"displayName":"Abhijit Biswas","userId":"07763541842867693542"},"user_tz":-330},"id":"c71XfVLuUkA1"},"outputs":[],"source":["# Loading the dataset\n","usersRDD = spark.sparkContext.textFile(\n","    \"/content/drive/MyDrive/Contents/Pyspark/PySpark Dataframe/users.dat\"\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1700646694830,"user":{"displayName":"Abhijit Biswas","userId":"07763541842867693542"},"user_tz":-330},"id":"ykawaLuYVBB6"},"outputs":[],"source":["# Define schema\n","schema_string = \"UserID Gender Age Occupation Zip-code\"\n","schema = StructType(\n","    [\n","        StructField(field_name, StringType(), True)\n","        for field_name in schema_string.split()\n","    ]\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":388,"status":"ok","timestamp":1700646698071,"user":{"displayName":"Abhijit Biswas","userId":"07763541842867693542"},"user_tz":-330},"id":"AEO_pSJaVFim"},"outputs":[],"source":["# Create DataFrame\n","row_rdd = usersRDD.map(lambda x: x.split(\"::\")).map(\n","    lambda x: (x[0], x[1], x[2], x[3], x[4])\n",")\n","users = spark.createDataFrame(row_rdd, schema)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1670,"status":"ok","timestamp":1700646703554,"user":{"displayName":"Abhijit Biswas","userId":"07763541842867693542"},"user_tz":-330},"id":"xW4jX7iDVG08","outputId":"9d9e043c-94f8-456f-cc18-fd65a18262b1"},"outputs":[{"name":"stdout","output_type":"stream","text":["+------+------+---+----------+--------+\n","|UserID|Gender|Age|Occupation|Zip-code|\n","+------+------+---+----------+--------+\n","|     1|     F|  1|        10|   48067|\n","|     2|     M| 56|        16|   70072|\n","|     3|     M| 25|        15|   55117|\n","|     4|     M| 45|         7|   02460|\n","|     5|     M| 25|        20|   55455|\n","|     6|     F| 50|         9|   55117|\n","|     7|     M| 35|         1|   06810|\n","|     8|     M| 25|        12|   11413|\n","|     9|     M| 25|        17|   61614|\n","|    10|     F| 35|         1|   95370|\n","|    11|     F| 25|         1|   04093|\n","|    12|     M| 25|        12|   32793|\n","|    13|     M| 45|         1|   93304|\n","|    14|     M| 35|         0|   60126|\n","|    15|     M| 25|         7|   22903|\n","|    16|     F| 35|         0|   20670|\n","|    17|     M| 50|         1|   95350|\n","|    18|     F| 18|         3|   95825|\n","|    19|     M|  1|        10|   48073|\n","|    20|     M| 25|        14|   55113|\n","+------+------+---+----------+--------+\n","only showing top 20 rows\n","\n"]}],"source":["# Show the output\n","users.show()"]},{"cell_type":"markdown","metadata":{"id":"7qYKyoJmUkip"},"source":["**Question 03**\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":434,"status":"ok","timestamp":1700646768129,"user":{"displayName":"Abhijit Biswas","userId":"07763541842867693542"},"user_tz":-330},"id":"RkxGCTWOUmgd"},"outputs":[{"ename":"NameError","evalue":"name 'spark' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Loading the dataset\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m movies \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241m.\u001b[39mread\u001b[38;5;241m.\u001b[39mtext(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/content/drive/MyDrive/Contents/Pyspark/PySpark Dataframe/movies.dat\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m movies\u001b[38;5;241m.\u001b[39mshow()\n","\u001b[1;31mNameError\u001b[0m: name 'spark' is not defined"]}],"source":["# Loading the dataset\n","movies = spark.read.text(\n","    \"/content/drive/MyDrive/Contents/Pyspark/PySpark Dataframe/movies.dat\"\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":420,"status":"ok","timestamp":1700646775467,"user":{"displayName":"Abhijit Biswas","userId":"07763541842867693542"},"user_tz":-330},"id":"5jpO1njdjfjw"},"outputs":[],"source":["# Split the columns using '::'\n","split_columns = movies.withColumn(\"split_data\", split(col(\"value\"), \"::\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1700646783975,"user":{"displayName":"Abhijit Biswas","userId":"07763541842867693542"},"user_tz":-330},"id":"-COGF2mjrqQv"},"outputs":[],"source":["# Extract the MovieID, Title, and Genres (Year) columns\n","extracted_df = split_columns.select(\n","    col(\"split_data\")[0].alias(\"MovieID\"),\n","    col(\"split_data\")[1].alias(\"Title\"),\n","    col(\"split_data\")[2].alias(\"Genres_Year\"),\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":400,"status":"ok","timestamp":1700646795480,"user":{"displayName":"Abhijit Biswas","userId":"07763541842867693542"},"user_tz":-330},"id":"W_q_njL6rr9R"},"outputs":[],"source":["# Extract Year and replace it in the Title and Genres columns\n","year_and_genres_df = (\n","    extracted_df.withColumn(\"Year\", regexp_extract(col(\"Title\"), \"\\\\((\\\\d{4})\\\\)\", 1))\n","    .withColumn(\"Title\", regexp_replace(col(\"Title\"), \"\\\\((\\\\d{4})\\\\)\", \"\"))\n","    .withColumn(\"Genres\", regexp_replace(col(\"Genres_Year\"), \"\\\\((\\\\d{4})\\\\)\", \"\"))\n","    .drop(\"Genres_Year\")\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2423,"status":"ok","timestamp":1700646800959,"user":{"displayName":"Abhijit Biswas","userId":"07763541842867693542"},"user_tz":-330},"id":"ik1gbHkCrtXk","outputId":"6423a588-df37-4fca-fcb9-d22c8161d96b"},"outputs":[{"ename":"NameError","evalue":"name 'year_and_genres_df' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Show the output\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43myear_and_genres_df\u001b[49m\u001b[38;5;241m.\u001b[39mshow(truncate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n","\u001b[1;31mNameError\u001b[0m: name 'year_and_genres_df' is not defined"]}],"source":["# Show the output\n","year_and_genres_df.show(truncate=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qBTQ3yVgPrgi"},"outputs":[],"source":["# Stop the SparkSession\n","# spark.stop()"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":0}
