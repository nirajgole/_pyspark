{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb341db1-66bf-48fa-be61-f5b651f5770a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542fd8f0-fe44-4cb0-87e5-508e23dae500",
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb4e051-3a88-44e6-a040-d42b088d436a",
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e308d0e5-5aef-4623-9404-765c127d198f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6846b603-07ed-43dc-8f0e-d0eed1750a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext(appName=\"RDD Ops\").getOrCreate()\n",
    "# Entry point for Spark CORE application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded0c40a-0514-4c34-9afa-3ac4e32f7192",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7e1fd6-2d12-40f3-b896-e77943b666db",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.textFile(\"d:\\\\data\\\\custs.txt\",5)\n",
    "# rdd is collection of strings\n",
    "rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e2527e-f5ae-46ea-b4fd-293ac017f56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7942d579-e4bb-431b-a1d4-dd256fe7dab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cf5223-eb07-486d-82dd-f526459e4309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get all the records where age > 40\n",
    "# 2. Get all the records where desig is missing\n",
    "# 3. Get all the records where age > 60 and desig is Pilot\n",
    "# 4. Get all the records where fname starts with \"S\"\n",
    "# 5. Get all the records where desig is ('Teacher','Pilot','Lawyer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb820f7-1ad8-43d7-9101-949313bd9742",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd1 = rdd.map(lambda str : str.split(\",\"))\n",
    "rdd1.first()\n",
    "rdd1.getNumPartitions()\n",
    "# rdd1 is collection List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71f1125-e2ec-431d-81f4-c35c846a6553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rdd2 = rdd1.filter(lambda lst : int(lst[3]) > 60 and lst[4]==\"Pilot\")\n",
    "rdd2 = rdd1.filter(lambda lst : lst[1][0]==\"S\")\n",
    "\n",
    "rdd2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9880abfe-4dfe-4503-b65a-d45a6c9a113c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Get all the records where desig is missing\n",
    "rdd3 = rdd1.filter(lambda lst : lst[4]  in ('Teacher','Pilot','Lawyer'))\n",
    "rdd3.take(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b86757-4bab-4e92-9399-e872a9bf250e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397e1a95-7854-4b32-91bf-66b7eefe1b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lazy Evaluation\n",
    "\n",
    "# Designation wise Count\n",
    "rdd = sc.textFile(\"d:\\\\data\\\\custs.txt\",5)\n",
    "rdd1 = rdd.map(lambda str : str.split(\",\"))\n",
    "rdd2 = rdd1.map(lambda lst : (lst[4],1))\n",
    "rdd3 = rdd2.reduceByKey(lambda v1,v2 : (v1+v2))\n",
    "rdd3.first()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03441d0a-351f-4630-bcc0-167e2da52d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading folder ( this will read all the files from that folder)\n",
    "rdd = sc.textFile(\"D:\\\\data\\\\output11\")\n",
    "rdd1.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531d5826-9e3f-4668-8a90-3136b429d439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividing the file's data into 05 partitions\n",
    "rdd = sc.textFile(\"d:\\\\data\\\\custs.txt\",5)\n",
    "rdd1 = rdd.map(lambda str : str.split(\",\")) \n",
    "rdd2 = rdd1.map(lambda lst : (lst[1][0],1)) \n",
    "# --stage 01\n",
    "# tasks 5\n",
    "\n",
    "rdd3 = rdd2.reduceByKey(lambda x1,x2 : (x1+x2))\n",
    "# --stage 02\n",
    "# tasks 5\n",
    "\n",
    "rdd4 = rdd3.sortBy(lambda x : x[1],ascending=False)\n",
    "# --stage 03\n",
    "\n",
    "rdd4.first()\n",
    "# In 3rd state, if action is \"first()\", there will be one task of action of \"count()\"\n",
    "# there will be total 05 tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83419fa-c6b7-496f-80cc-eb383493daff",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.textFile(\"d:\\\\data\\\\custs.txt\",5)\n",
    "rdd1 = rdd.map(lambda str : str.split(\",\")) \n",
    "rdd2 = rdd1.map(lambda lst : (lst[1][0],1)) \n",
    "rdd2.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318a1acf-f9c6-4711-8961-8ffea44e9fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rdd method : flatMap\n",
    "\n",
    "# WordCount program\n",
    "\n",
    "# Sample Data\n",
    "# testing in pyspark application\n",
    "# testing pyspark application\n",
    "# testing \n",
    "# testing pyspark application\n",
    "\n",
    "rdd = sc.textFile(\"d:\\\\data\\\\words.txt\",5)\\\n",
    "          .flatMap(lambda str : str.split(\" \"))\\\n",
    "          .map(lambda word : (word,1))\\\n",
    "          .reduceByKey(lambda v1,v2 : (v1+v2))\\\n",
    "          .sortBy(lambda tu : tu[1],False)\\\n",
    "          .collect()\n",
    "          \n",
    "# Another way to create a RDD. Method \"parallelize\" \n",
    "# requires input as sequence of some objects\n",
    "rd1 = sc.parallelize(rdd)\n",
    "\n",
    "rd1.getNumPartitions()\n",
    "rd1.saveAsTextFile(\"d:\\\\data\\\\output1\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae936ce-79b7-42e1-9a79-7561aee7297c",
   "metadata": {},
   "source": [
    "### Joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7966bc3-ccd6-49d6-906d-afd184da5796",
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_rdd = sc.textFile(\"d:\\\\data\\\\custs.txt\")\\\n",
    "        .map(lambda str : str.split(\",\"))\\\n",
    "        .map(lambda lst : (lst[0],lst[1]))\n",
    "\n",
    "txn_rdd = sc.textFile(\"d:\\\\data\\\\txn.txt\")\\\n",
    "        .map(lambda str : str.split(\",\"))\\\n",
    "        .map(lambda lst : (lst[2],float(lst[3])))\n",
    "\n",
    "joined = txn_rdd.join(cust_rdd)\n",
    "\n",
    "joined = txn_rdd.\n",
    "# ('4002613', (98.81, 'Hugh'))=> ('4002613','Hugh',98.81)\n",
    "\n",
    "result = joined.map(lambda tu : (tu[0],tu[1][1],tu[1][0]))\n",
    "\n",
    "result.take(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3619c79e-3cfb-4771-a981-b80b16c57917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[296] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a08e6d16-d2c1-40b7-ba69-43ff40d1a281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('4002613', 'Hugh', 98.81)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "abc887bb-0552-4545-b488-3bb986f78cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import StorageLevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5c29939f-e2d7-441f-9ec2-22f5ed6c6ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[296] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c10f38a5-ac6a-414a-a95c-3b24fe1d77e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[296] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.persist(StorageLevel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0cb496df-5a4f-450a-8ffc-41a0f7338a58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('4002613', 'Hugh', 98.81)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2041e8-c610-4e9f-b149-d0918d57681e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
