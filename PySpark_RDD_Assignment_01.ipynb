{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27584,"status":"ok","timestamp":1700644392193,"user":{"displayName":"Abhijit Biswas","userId":"07763541842867693542"},"user_tz":-330},"id":"apRK3KIo1m6H","outputId":"f9cca8ea-06fa-45e4-ba6f-afe9d477f46c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n","/content/drive/MyDrive\n","\u001b[0m\u001b[01;34m'01. Big Data Hadoop'\u001b[0m/\n","\u001b[01;34m'02. Data Science with R'\u001b[0m/\n","\u001b[01;34m'03. Microsoft Excel'\u001b[0m/\n","\u001b[01;34m'04. AngularJs'\u001b[0m/\n","\u001b[01;34m'05. Linux'\u001b[0m/\n","\u001b[01;34m'06. AWS'\u001b[0m/\n","\u001b[01;34m'07. AWS Big Data'\u001b[0m/\n","'10 may devops quiz and discussion.gsheet'\n","'Advanced Certification in Cloud & DevOps by  Electronics & ICT Academy IIT Guwahati.pptx'\n","'Advanced Certification in Cyber Security Electronics & ICT Academy IIT Guwahati.pptx'\n","'Advanced Certification in UI UX Design Strategy Electronics & ICT Academy IIT Guwahati.pptx'\n"," Agreement.gdoc\n","'Banner (1).png'\n","'Banner (2).png'\n"," Banner.png\n","\u001b[01;34m'Colab Notebooks'\u001b[0m/\n","'Content Repository.gsheet'\n"," \u001b[01;34mContents\u001b[0m/\n","'Content Team Work.gsheet'\n","'Copy of books.csv'\n","'Copy of book_tags.csv'\n","'Copy of Copy of PRT DA 17th Sep.gsheet'\n","' Copy of.gsheet'\n","'Copy of Process Diagrams by Slidesgo.gslides'\n","'Copy of ratings.csv'\n","'Copy of recommender project.R'\n","'Copy of tags.csv'\n","'Copy of Trichrome Wheel – by PresentationGO.gslides'\n","\u001b[01;34m'Data Engineering'\u001b[0m/\n","'Data Engineering Cirriculum.gsheet'\n","'Data Engineering Project 01 - Data Flow Fusion.gdoc'\n","'Data Engineering Project 02 - Stream Flow.gdoc'\n","'Data Engineering Table of Content.gsheet'\n","'Docker and K8s Quiz.gform'\n","'Excel Video 06 Script.gdoc'\n","'Excel Video 07 Script.gdoc'\n","'Excel Video 13 Script.gdoc'\n","'Excel Video 15 Script.gdoc'\n","'Full Stack Course.gsheet'\n","'Git and Jenkins Quiz.gform'\n","\u001b[01;34m'Good Question'\u001b[0m/\n","\u001b[01;34m'Google Files'\u001b[0m/\n","'Hadoop Course Updates.gsheet'\n","\u001b[01;34m'Hadoop Full Course - Avinash'\u001b[0m/\n","'HTML and CSS Code.gdoc'\n"," image1.jpg\n"," \u001b[01;34mInstallations\u001b[0m/\n","\u001b[01;34m'Intellipaat Live Classes'\u001b[0m/\n","'Intellipaat Premier League 2023 - Tech Titans.gsheet'\n","'Java Fundamentals Script.gdoc'\n"," Location.png\n"," Module8_Lecture4.mp4\n","'My Resources .gsheet'\n","\u001b[01;34m\"Prashant's Drive\"\u001b[0m/\n","'PRT Emails.gform'\n","'Pyspark Table of Content.gsheet'\n"," \u001b[01;34mPython\u001b[0m/\n","\u001b[01;34m'Quiz Links'\u001b[0m/\n"," Screenshot_2.png\n","'SyncData between Sheets (1).gsheet'\n","'SyncData between Sheets.gsheet'\n","'Untitled Diagram'\n","'Untitled document.gdoc'\n","'Untitled spreadsheet (Created by Sheetgo on Oct 28, 2023, 05:53 PM).xlsx'\n","'Untitled spreadsheet.gsheet'\n","/content/drive/MyDrive/Contents\n","\u001b[0m\u001b[01;34m'AWS Solution Architect Course'\u001b[0m/  \u001b[01;34m'Google Foobar'\u001b[0m/               \u001b[01;34m'MongoDB Content'\u001b[0m/\n"," \u001b[01;34mBackend\u001b[0m/                          \u001b[01;34mHadoop\u001b[0m/                        \u001b[01;34mPyspark\u001b[0m/\n"," \u001b[01;34mcheckpoint\u001b[0m/                      \u001b[01;34m'HTML & CSS'\u001b[0m/                  \u001b[01;34m'React Js'\u001b[0m/\n","\u001b[01;34m'Data Engineering'\u001b[0m/               \u001b[01;34m'Intellipaat Content Format'\u001b[0m/   \u001b[01;34mspark-warehouse\u001b[0m/\n","\u001b[01;34m'Electric Vehicle'\u001b[0m/               \u001b[01;34m'Java Fundamentals'\u001b[0m/           \u001b[01;34m'Version Control with Git'\u001b[0m/\n","\u001b[01;34m'Evaluation Quiz'\u001b[0m/                \u001b[01;34m'Java OOPS'\u001b[0m/\n","\u001b[01;34m'Generative AI'\u001b[0m/                   \u001b[01;34mJavaScript\u001b[0m/\n"]}],"source":["# importing the required library\n","from google.colab import drive\n","# mounting google drive to Collab\n","drive.mount('/content/drive')\n","# moving around in google drive\n","%cd drive/MyDrive\n","# Listing all the files/folders present\n","%ls\n","# moving around in google drive\n","%cd  Contents/\n","# Listing all the files/folders present\n","%ls"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":52407,"status":"ok","timestamp":1700644461356,"user":{"displayName":"Abhijit Biswas","userId":"07763541842867693542"},"user_tz":-330},"id":"cnqBsKFc11hY","outputId":"efec06e4-9ad2-4ccf-f6a6-4e029caf3d98"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting pyspark\n","  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n","Building wheels for collected packages: pyspark\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425344 sha256=3be83e832a1d051bd8754d1dce226c4ccfe0061c9bfbe1a74e60f85404840caa\n","  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n","Successfully built pyspark\n","Installing collected packages: pyspark\n","Successfully installed pyspark-3.5.0\n"]}],"source":["# installing the pyspark library.\n","!pip install pyspark"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":219},"executionInfo":{"elapsed":10425,"status":"ok","timestamp":1700644499765,"user":{"displayName":"Abhijit Biswas","userId":"07763541842867693542"},"user_tz":-330},"id":"X485ZnKE3hti","outputId":"4801aa53-2dd4-46db-8788-d2f899ad33ad"},"outputs":[{"data":{"text/html":["\n","            <div>\n","                <p><b>SparkSession - in-memory</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://91ebbc00c671:4040\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.5.0</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local[*]</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>PySpark RDD Assignment 01</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "],"text/plain":["<pyspark.sql.session.SparkSession at 0x7a0bd8228940>"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# importing SparkSession from pyspark.sql library\n","from pyspark.sql import SparkSession\n","from pyspark.sql.types import StructType,StructField, IntegerType, StringType\n","\n","# What is the differnece between SparkSession and SparkContext\n","# SparkContext was the entry point for programming Spark before Spark 2.0. It represented the connection to a Spark cluster and was responsible for coordinating the execution of tasks.\n","# It was used to create RDDs (Resilient Distributed Datasets), which are the fundamental data structures in Spark for distributed computation.\n","# SparkContext handled low-level functionalities like distributing and scheduling tasks, managing memory, and interacting with storage systems.\n","# However, with the introduction of SparkSession, most of the functionality of SparkContext was encapsulated within the new session abstraction.\n","\n","# SparkSession is the entry point for programming Spark applications starting from Spark 2.0.\n","# It encapsulates both the SparkContext and additional context-related configuration.\n","# It provides a unified interface for working with structured data using DataFrames and Datasets, which offer optimizations and benefits over RDDs.\n","# SparkSession also manages various context-specific settings and configurations, like SQL configuration, Hive integration, and more.\n","# It simplifies the process of working with different Spark libraries (SQL, Streaming, MLlib, GraphX) by providing a consistent API.\n","\n","# initializing a SparkSession taking in consideration all the cores in local system and giving a name to the Application as \"SparkSession\"\n","spark = SparkSession.builder.master(\"local[*]\").appName(\"PySpark RDD Assignment 01\").getOrCreate()\n","\n","# Printing out the value of spark variable that stores the spark session.\n","spark"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":3432,"status":"ok","timestamp":1700644588891,"user":{"displayName":"Abhijit Biswas","userId":"07763541842867693542"},"user_tz":-330},"id":"sXUJFBhf5PSB"},"outputs":[],"source":["# Load the text file into a DataFrame\n","text_df = spark.read.text(\"/content/drive/MyDrive/Contents/Pyspark/PySpark RDD/Assignment 01/RomeoJuliet.txt\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VPivIWgTUA1y"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"sP6DsRSyACK1"},"source":["**Question 01**\n","\n","\n","\n"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":537,"status":"ok","timestamp":1700644628736,"user":{"displayName":"Abhijit Biswas","userId":"07763541842867693542"},"user_tz":-330},"id":"SgWe0YES8uZg"},"outputs":[],"source":["import re\n","def clean_and_normalize(text):\n","    # Remove punctuation and convert to lowercase\n","    return re.sub(r'[^\\w\\s]', '', text).lower()"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":1554,"status":"ok","timestamp":1700644635901,"user":{"displayName":"Abhijit Biswas","userId":"07763541842867693542"},"user_tz":-330},"id":"bGHXliPz5huh"},"outputs":[],"source":["# Split each line into words using flatMap\n","# words = text_df.rdd.flatMap(lambda line: clean_and_normalize(line[0]).split(\" \"))\n","words = text_df.rdd.flatMap(lambda line: print(line))"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1700644662260,"user":{"displayName":"Abhijit Biswas","userId":"07763541842867693542"},"user_tz":-330},"id":"U0Nn9w8N9wtZ"},"outputs":[],"source":["# Filter out empty strings\n","non_empty_words = words.filter(lambda word: len(word) > 0)"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":397,"status":"ok","timestamp":1700644672207,"user":{"displayName":"Abhijit Biswas","userId":"07763541842867693542"},"user_tz":-330},"id":"xw1Ec4kU5oda"},"outputs":[],"source":["# Map each word to a key-value pair (word, 1)\n","word_counts = non_empty_words.map(lambda word: (word, 1))"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":945,"status":"ok","timestamp":1700644677767,"user":{"displayName":"Abhijit Biswas","userId":"07763541842867693542"},"user_tz":-330},"id":"6IUOM9-W5qM4"},"outputs":[],"source":["# Reduce by key to get the count of each word\n","result = word_counts.reduceByKey(lambda x, y: x + y)"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":5889,"status":"ok","timestamp":1700644694813,"user":{"displayName":"Abhijit Biswas","userId":"07763541842867693542"},"user_tz":-330},"id":"3b3g-lTF5saz"},"outputs":[],"source":["# Convert the RDD to a DataFrame\n","result_df = result.toDF([\"Word\", \"Occurences\"])"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":411,"status":"ok","timestamp":1700644717897,"user":{"displayName":"Abhijit Biswas","userId":"07763541842867693542"},"user_tz":-330},"id":"stiCVBw99Vsm"},"outputs":[],"source":["# Sort the DataFrame by the 'count' column in descending order\n","sorted_result_df = result_df.orderBy(\"Occurences\", ascending=False)"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5671,"status":"ok","timestamp":1700644730101,"user":{"displayName":"Abhijit Biswas","userId":"07763541842867693542"},"user_tz":-330},"id":"-1P13C0Q5tyF","outputId":"bb1853bc-ea1b-4a88-ae13-b95e8f90da39"},"outputs":[{"name":"stdout","output_type":"stream","text":["+--------+----------+\n","|Word    |Occurences|\n","+--------+----------+\n","|the     |1372      |\n","|a       |563       |\n","|to      |506       |\n","|of      |469       |\n","|romeo   |464       |\n","|and     |461       |\n","|in      |258       |\n","|juliet  |251       |\n","|is      |246       |\n","|i       |224       |\n","|he      |193       |\n","|on      |178       |\n","|his     |170       |\n","|with    |159       |\n","|that    |146       |\n","|as      |145       |\n","|mercutio|143       |\n","|her     |138       |\n","|my      |136       |\n","|from    |134       |\n","|capulet |133       |\n","|not     |129       |\n","|it      |124       |\n","|into    |115       |\n","|thou    |114       |\n","+--------+----------+\n","only showing top 25 rows\n","\n"]}],"source":["# Showing the result of wordcount\n","sorted_result_df.show(25, truncate = False)"]},{"cell_type":"markdown","metadata":{"id":"IdnYrPOb-yoC"},"source":["**Optional Question**"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2690,"status":"ok","timestamp":1700644779117,"user":{"displayName":"Abhijit Biswas","userId":"07763541842867693542"},"user_tz":-330},"id":"nGjXvU_P-7-x","outputId":"7eb5d402-f185-4735-975d-73cf47e687c7"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]},{"data":{"text/plain":["True"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["import nltk\n","nltk.download('stopwords')"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":957,"status":"ok","timestamp":1700644803485,"user":{"displayName":"Abhijit Biswas","userId":"07763541842867693542"},"user_tz":-330},"id":"MWM2n-m6AYQq"},"outputs":[],"source":["import re\n","def clean_and_normalize(text):\n","    # Remove punctuation and convert to lowercase\n","    return re.sub(r'[^\\w\\s]', '', text).lower()"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1700644803485,"user":{"displayName":"Abhijit Biswas","userId":"07763541842867693542"},"user_tz":-330},"id":"cUN7RwCY_YiH"},"outputs":[],"source":["# Clean and normalize the text, split each line into words using flatMap\n","words = text_df.rdd.flatMap(lambda line: clean_and_normalize(line[0]).split(\" \"))"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1700644804049,"user":{"displayName":"Abhijit Biswas","userId":"07763541842867693542"},"user_tz":-330},"id":"GuWchH9kAs9a"},"outputs":[],"source":["# Filter out empty strings\n","non_empty_words = words.filter(lambda word: len(word) > 0)"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":352,"status":"ok","timestamp":1700644806616,"user":{"displayName":"Abhijit Biswas","userId":"07763541842867693542"},"user_tz":-330},"id":"Gd639-iTAu7L"},"outputs":[],"source":["# Remove stopwords using NLTK\n","stopwords = nltk.corpus.stopwords.words('english')\n","filtered_words = non_empty_words.filter(lambda word: word not in stopwords)"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1700644809255,"user":{"displayName":"Abhijit Biswas","userId":"07763541842867693542"},"user_tz":-330},"id":"Vu7wWEY0Awbe"},"outputs":[],"source":["# Map each word to a key-value pair (word, 1)\n","word_counts = filtered_words.map(lambda word: (word, 1))"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1700644810837,"user":{"displayName":"Abhijit Biswas","userId":"07763541842867693542"},"user_tz":-330},"id":"uA1QqvqdAx10"},"outputs":[],"source":["# Reduce by key to get the count of each word\n","result = word_counts.reduceByKey(lambda x, y: x + y)"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":1075,"status":"ok","timestamp":1700644813916,"user":{"displayName":"Abhijit Biswas","userId":"07763541842867693542"},"user_tz":-330},"id":"5JAnfwWzAzep"},"outputs":[],"source":["# Convert the RDD to a DataFrame\n","result_df = result.toDF([\"Word\", \"Occurences\"])"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":351,"status":"ok","timestamp":1700644818797,"user":{"displayName":"Abhijit Biswas","userId":"07763541842867693542"},"user_tz":-330},"id":"UdMBFm5pA1De"},"outputs":[],"source":["# Sort the DataFrame by the 'count' column in descending order\n","sorted_result_df = result_df.orderBy(\"Occurences\", ascending=False)"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":974,"status":"ok","timestamp":1700644825449,"user":{"displayName":"Abhijit Biswas","userId":"07763541842867693542"},"user_tz":-330},"id":"1EnE_7JSA2XJ","outputId":"02fe9ab7-cfa8-4f36-d866-63c96762d5bc"},"outputs":[{"name":"stdout","output_type":"stream","text":["+--------+----------+\n","|Word    |Occurences|\n","+--------+----------+\n","|romeo   |464       |\n","|juliet  |251       |\n","|mercutio|143       |\n","|capulet |133       |\n","|thou    |114       |\n","|benvolio|111       |\n","|night   |111       |\n","|father  |98        |\n","|ext     |97        |\n","|close   |96        |\n","|nurse   |96        |\n","|cont    |92        |\n","|int     |88        |\n","|cut     |87        |\n","|car     |84        |\n","|love    |82        |\n","|laurence|81        |\n","|tybalt  |79        |\n","|gloria  |71        |\n","|day     |66        |\n","|thy     |62        |\n","|back    |58        |\n","|thee    |56        |\n","|eyes    |53        |\n","|toward  |52        |\n","+--------+----------+\n","only showing top 25 rows\n","\n"]}],"source":["# Showing the result of wordcount\n","sorted_result_df.show(25, truncate = False)"]},{"cell_type":"markdown","metadata":{"id":"ouyhcvJq_Z0q"},"source":["**Stopping all the resources**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_tjDQkVI31U0"},"outputs":[],"source":["# Stop the SparkSession\n","spark.stop()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XTgmeuQ76pbS"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
